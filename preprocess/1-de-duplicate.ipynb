{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', '互联网招聘网站数据-20190109')\n",
    "files = ['1545993937965.csv', '1545995178836.csv', '1545994719214.csv', '1545993524166.csv', '1545994117111.csv',\n",
    "         '1545993734962.csv', '1545995482689.csv', '1545994520923.csv', '1545993316117.csv', '1545996463690.csv',\n",
    "         '1545995875667.csv', '1545996273574.csv', '1545995679248.csv', '1545993098203.csv', '1545995371123.csv',\n",
    "         '1545996077068.csv', '1545994918682.csv', '1545994993854.csv', '1545994322721.csv']\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    with open(os.path.join(dir_path, file), 'rb') as f, open(os.path.join(os.path.dirname(dir_path), file), 'wb') as f1:\n",
    "        line = f.readline()\n",
    "        cnt = line.count(b',')\n",
    "        while line:\n",
    "            if line.count(b',') != cnt:\n",
    "                line = line.strip(b'\\n')\n",
    "                line += f.readline()\n",
    "                continue\n",
    "            f1.write(line)\n",
    "            line = f.readline().replace(b'\"', b'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = os.path.dirname(dir_path)\n",
    "# files_path = [os.path.join(dir_path, file) for file in files]\n",
    "# df = pd.read_csv(files_path[0], encoding='gb18030', parse_dates=['page_publish_time'],\n",
    "#                  usecols=['page_url', 'pos_desc', 'page_publish_time', 'pos_count', 'page_province',\n",
    "#                           'pos_class', 'pos_industry', 'site_name', 'pos_age', 'pos_name', 'pos_welfare',\n",
    "#                           'page_city', 'old_industry', 'deliver_count', 'pos_salary', 'com_name',\n",
    "#                           'pos_education', 'pos_experience', 'read_count'])\n",
    "#\n",
    "# for file_path in files_path[1:]:\n",
    "#     df = df.append(pd.read_csv(file_path,\n",
    "#                                encoding='gb18030',\n",
    "#                                parse_dates=['page_publish_time'],\n",
    "#                                usecols=['page_url', 'pos_desc', 'page_publish_time', 'pos_count', 'page_province',\n",
    "#                                         'pos_class', 'pos_industry', 'site_name', 'pos_age', 'pos_name', 'pos_welfare',\n",
    "#                                         'page_city', 'old_industry', 'deliver_count', 'pos_salary', 'com_name',\n",
    "#                                         'pos_education', 'pos_experience', 'read_count']),\n",
    "#                    ignore_index=False)\n",
    "#\n",
    "# df.shape # (16892402, 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "上方注释的代码执行完后，本 notebook 占用内存已超过25G，故不推荐直接运行上方代码。\n",
    "\n",
    "根据我们的观察，发现数据中有很多重复的链接，以及公司名和职位名。我们尝试了不同的去重策略，结果如下："
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df1 = df.drop_duplicates(subset=['page_url'], keep='last')\n",
    "# df1.shape  # (13680314, 19)\n",
    "\n",
    "# df1 = df.drop_duplicates(subset=['pos_name', 'com_name'], keep='last')\n",
    "# df1.shape  # (2950631, 19)\n",
    "\n",
    "# df1 = df.drop_duplicates(subset=['pos_name', 'com_name', 'page_city'])\n",
    "# df1.shape  # (3926646, 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们尝试了三种去重方法：\n",
    "1. 根据`page_url`属性去重，此时还剩余 13680314 条数据。\n",
    "1. 根据`pos_name`、`com_name` 去重，此时还剩 2950631 条数据。\n",
    "1. 根据`pos_name`、`com_name` 和 `page_city` 去重，此时还剩 3926646 条数据。\n",
    "\n",
    "使用不同的去重策略得到的最终数据集大小不同，这让我们对数据集的内容产生了兴趣，我们通过文本编辑器查看了重复的数据之间的关系，发现重复的记录中，`_id`\n",
    "属性在所有的数据文件中是唯一的，但我们没有使用该属性。对于重复的数据的其他属性，我们发现，`page_url` 重复度很大，我们推测，当同一家公司发布同一个\n",
    "岗位时，通过编辑岗位的相关信息，可能并不会改变该岗位的链接属性。且有许多重复数据，仅 `deliver_count` 和 `read_count` 不同。综合考虑下，我们\n",
    "决定使用第三种去重方法，并保留最后一条数据。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993098203.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993098203.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993316117.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993316117.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993524166.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993524166.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993734962.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993734962.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993937965.csv start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\rxg\\desktop\\code\\dataminingbigproject\\.venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3169: DtypeWarning: Columns (4,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545993937965.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994117111.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994117111.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994322721.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994322721.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994520923.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994520923.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994719214.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994719214.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994918682.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994918682.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994993854.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545994993854.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995178836.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995178836.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995371123.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995371123.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995482689.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995482689.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995679248.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995679248.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995875667.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545995875667.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545996077068.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545996077068.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545996273574.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545996273574.csv start\n",
      "read C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545996463690.csv start\n",
      "de-duplicate C:\\Users\\rxg\\Desktop\\Code\\DataMiningBigProject\\data\\1545996463690.csv start\n"
     ]
    },
    {
     "data": {
      "text/plain": "(3926646, 19)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = os.path.dirname(dir_path)\n",
    "files_path = [os.path.join(dir_path, file) for file in files]\n",
    "print(f'read {files_path[0]} start')\n",
    "df = pd.read_csv(files_path[0], encoding='gb18030', parse_dates=['page_publish_time'],\n",
    "                 usecols=['page_url', 'pos_desc', 'page_publish_time', 'pos_count', 'page_province',\n",
    "                          'pos_class', 'pos_industry', 'site_name', 'pos_age', 'pos_name', 'pos_welfare',\n",
    "                          'page_city', 'old_industry', 'deliver_count', 'pos_salary', 'com_name',\n",
    "                          'pos_education', 'pos_experience', 'read_count'])\n",
    "print(f'de-duplicate {files_path[0]} start')\n",
    "df.drop_duplicates(subset=['pos_name', 'com_name', 'page_city'], keep='last', inplace=True)\n",
    "\n",
    "for file_path in files_path[1:]:\n",
    "    print(f'read {file_path} start')\n",
    "    df = df.append(pd.read_csv(file_path,\n",
    "                               encoding='gb18030',\n",
    "                               parse_dates=['page_publish_time'],\n",
    "                               usecols=['page_url', 'pos_desc', 'page_publish_time', 'pos_count', 'page_province',\n",
    "                                        'pos_class', 'pos_industry', 'site_name', 'pos_age', 'pos_name', 'pos_welfare',\n",
    "                                        'page_city', 'old_industry', 'deliver_count', 'pos_salary', 'com_name',\n",
    "                                        'pos_education', 'pos_experience', 'read_count']),\n",
    "                   ignore_index=False)\n",
    "    print(f'de-duplicate {file_path} start')\n",
    "    df.drop_duplicates(subset=['pos_name', 'com_name', 'page_city'], keep='last', inplace=True)\n",
    "\n",
    "df.shape # (3926646, 19)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# save file\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.to_csv(os.path.join(dir_path, '1-de-duplicate.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            page_url  \\\n0  http://jobs.zhaopin.com/CC690972424J0013190060...   \n1  http://zz.58.com/tech/34770954823372x.shtml?ps...   \n2  http://zz.58.com/zhuanye/34568001532484x.shtml...   \n3        http://jobs.zhaopin.com/624002185250004.htm   \n4  http://cq.58.com/yewu/25035685221419x.shtml?ps...   \n\n                                            pos_desc page_publish_time  \\\n0  任职资格： 1.男性，年龄18-40岁；能适应倒班制；要求熟练工； 2.工作地点：江苏徐州丰...        2018-07-17   \n1  兼职寒暑假短期工勿扰，不符合条件者勿扰  任职要求：  1，男女不限，18-27岁，专科及以...        2018-07-17   \n2  岗位职责：  1、咨询电话的接听，做好相应的信息记录；  2、定期对记录的咨询信息进行回访，...        2018-07-17   \n3  岗位职责： 1、负责产品的验收评估，并编写产品评估报告； 2、负责产品应用技术研发； 3、解...        2018-07-17   \n4  岗位职责：  1、负责根据客户的要求，给用户提供专业的知识咨询和服务；  2、负责推荐保险种...        2018-07-17   \n\n   pos_count page_province    pos_class pos_industry site_name  pos_age  \\\n0       10.0      410000.0        生产/制造         H018      智联招聘      0.0   \n1        3.0      410000.0     网络/通信/电子         H004      58同城      0.0   \n2        2.0      410000.0  法律/教育/翻译/出版         H007      58同城      0.0   \n3        1.0      340000.0        生产/制造         H009      智联招聘      0.0   \n4        3.0      500000.0  销售/客服/采购/淘宝         H008      58同城      0.0   \n\n      pos_name             pos_welfare page_city   old_industry  \\\n0     数控车床/磨床工                     NaN  410300.0  大型设备/机电设备/重工业   \n1  初级网站架构设计师餐补  五险一金 周末双休 年底双薪 饭补 加班补助  410100.0          计算机硬件   \n2    包食宿急聘课程顾问           加班补助 房补 包住 包吃  410100.0       教育/科研/培训   \n3      技术应用工程师                五险一金免费班车  340400.0       石油/石化/化工   \n4   急急急+销售客户经理               周末双休 免费培训  500100.0             保险   \n\n   deliver_count  pos_salary                   com_name pos_education  \\\n0            0.0   4001-6000                 江苏巨杰机电有限公司            中技   \n1            0.0   4000-6000               河南洽普网络科技有限公司            大专   \n2            3.0   3000-5000             郑州市二七区你好外语培训学校            大专   \n3            0.0  3000-5000?              清远升华新材料科技有限公司            不限   \n4           34.0   5000-8000  中国平安人寿保险股份有限公司重庆分公司（平安保险）          学历不限   \n\n  pos_experience  read_count  \n0           1-3年         0.0  \n1    经验不限，可接收应届生         2.0  \n2    1-2年，可接收应届生       102.0  \n3             不限         0.0  \n4    经验不限，可接收应届生      2153.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_url</th>\n      <th>pos_desc</th>\n      <th>page_publish_time</th>\n      <th>pos_count</th>\n      <th>page_province</th>\n      <th>pos_class</th>\n      <th>pos_industry</th>\n      <th>site_name</th>\n      <th>pos_age</th>\n      <th>pos_name</th>\n      <th>pos_welfare</th>\n      <th>page_city</th>\n      <th>old_industry</th>\n      <th>deliver_count</th>\n      <th>pos_salary</th>\n      <th>com_name</th>\n      <th>pos_education</th>\n      <th>pos_experience</th>\n      <th>read_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://jobs.zhaopin.com/CC690972424J0013190060...</td>\n      <td>任职资格： 1.男性，年龄18-40岁；能适应倒班制；要求熟练工； 2.工作地点：江苏徐州丰...</td>\n      <td>2018-07-17</td>\n      <td>10.0</td>\n      <td>410000.0</td>\n      <td>生产/制造</td>\n      <td>H018</td>\n      <td>智联招聘</td>\n      <td>0.0</td>\n      <td>数控车床/磨床工</td>\n      <td>NaN</td>\n      <td>410300.0</td>\n      <td>大型设备/机电设备/重工业</td>\n      <td>0.0</td>\n      <td>4001-6000</td>\n      <td>江苏巨杰机电有限公司</td>\n      <td>中技</td>\n      <td>1-3年</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://zz.58.com/tech/34770954823372x.shtml?ps...</td>\n      <td>兼职寒暑假短期工勿扰，不符合条件者勿扰  任职要求：  1，男女不限，18-27岁，专科及以...</td>\n      <td>2018-07-17</td>\n      <td>3.0</td>\n      <td>410000.0</td>\n      <td>网络/通信/电子</td>\n      <td>H004</td>\n      <td>58同城</td>\n      <td>0.0</td>\n      <td>初级网站架构设计师餐补</td>\n      <td>五险一金 周末双休 年底双薪 饭补 加班补助</td>\n      <td>410100.0</td>\n      <td>计算机硬件</td>\n      <td>0.0</td>\n      <td>4000-6000</td>\n      <td>河南洽普网络科技有限公司</td>\n      <td>大专</td>\n      <td>经验不限，可接收应届生</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://zz.58.com/zhuanye/34568001532484x.shtml...</td>\n      <td>岗位职责：  1、咨询电话的接听，做好相应的信息记录；  2、定期对记录的咨询信息进行回访，...</td>\n      <td>2018-07-17</td>\n      <td>2.0</td>\n      <td>410000.0</td>\n      <td>法律/教育/翻译/出版</td>\n      <td>H007</td>\n      <td>58同城</td>\n      <td>0.0</td>\n      <td>包食宿急聘课程顾问</td>\n      <td>加班补助 房补 包住 包吃</td>\n      <td>410100.0</td>\n      <td>教育/科研/培训</td>\n      <td>3.0</td>\n      <td>3000-5000</td>\n      <td>郑州市二七区你好外语培训学校</td>\n      <td>大专</td>\n      <td>1-2年，可接收应届生</td>\n      <td>102.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://jobs.zhaopin.com/624002185250004.htm</td>\n      <td>岗位职责： 1、负责产品的验收评估，并编写产品评估报告； 2、负责产品应用技术研发； 3、解...</td>\n      <td>2018-07-17</td>\n      <td>1.0</td>\n      <td>340000.0</td>\n      <td>生产/制造</td>\n      <td>H009</td>\n      <td>智联招聘</td>\n      <td>0.0</td>\n      <td>技术应用工程师</td>\n      <td>五险一金免费班车</td>\n      <td>340400.0</td>\n      <td>石油/石化/化工</td>\n      <td>0.0</td>\n      <td>3000-5000?</td>\n      <td>清远升华新材料科技有限公司</td>\n      <td>不限</td>\n      <td>不限</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://cq.58.com/yewu/25035685221419x.shtml?ps...</td>\n      <td>岗位职责：  1、负责根据客户的要求，给用户提供专业的知识咨询和服务；  2、负责推荐保险种...</td>\n      <td>2018-07-17</td>\n      <td>3.0</td>\n      <td>500000.0</td>\n      <td>销售/客服/采购/淘宝</td>\n      <td>H008</td>\n      <td>58同城</td>\n      <td>0.0</td>\n      <td>急急急+销售客户经理</td>\n      <td>周末双休 免费培训</td>\n      <td>500100.0</td>\n      <td>保险</td>\n      <td>34.0</td>\n      <td>5000-8000</td>\n      <td>中国平安人寿保险股份有限公司重庆分公司（平安保险）</td>\n      <td>学历不限</td>\n      <td>经验不限，可接收应届生</td>\n      <td>2153.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "去重完成后，总共 3926646 行，19列数据。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "page_url             3926646\npos_desc             3926646\npage_publish_time    3926646\npos_count            3926646\npage_province        3926586\npos_class            3926646\npos_industry         3926646\nsite_name            3926646\npos_age              3926646\npos_name             3926646\npos_welfare          3637882\npage_city            3914544\nold_industry         3926646\ndeliver_count        3926646\npos_salary           3926646\ncom_name             3926646\npos_education        3926646\npos_experience       3926646\nread_count           3926646\ndtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}